# íŒ€ì› A: ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ ë‹´ë‹¹ ê°€ì´ë“œ

## ğŸ“‹ ì—­í•  ê°œìš”

**ëª©í‘œ:** "ë¶„ì„í•  ì¬ë£Œ(ë¦¬ë·° ë°ì´í„°)ë¥¼ ê¹¨ë—í•˜ê²Œ ì¤€ë¹„í•œë‹¤."

ë„¤ì´ë²„ ì‡¼í•‘ê³¼ iHerbì—ì„œ ì œí’ˆ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ê³ , í•„ìš”í•œ ë©”íƒ€ë°ì´í„°(ì¬êµ¬ë§¤ ì—¬ë¶€, ì‚¬ìš© ê¸°ê°„ ë“±)ë¥¼ ì¶”ì¶œí•˜ì—¬ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

---

## ğŸ¯ ìƒì„¸ ë¯¸ì…˜

### 1. ë„¤ì´ë²„ ì‡¼í•‘/iHerb URLì—ì„œ ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘
- URL ì…ë ¥ ë°›ê¸°
- ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
- íƒœê·¸ ì •ë³´ ì¶”ì¶œ (ì¬êµ¬ë§¤, í•œë‹¬ì‚¬ìš©)
- í‰ì , ì‘ì„±ì¼ ë“± ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘

### 2. ë°ì´í„° ì •ì œ ë° CSV ì €ì¥
- ì¤‘ë³µ ë¦¬ë·° ì œê±°
- íŠ¹ìˆ˜ë¬¸ì ë° ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
- íƒœê·¸ ì •ê·œí™”
- CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
flowchart TD
    Start[ì‚¬ìš©ì URL ì…ë ¥] --> Validate{URL ìœ íš¨ì„± ê²€ì‚¬}
    Validate -->|ìœ íš¨| Detect{URL íƒ€ì… ê°ì§€}
    Validate -->|ë¬´íš¨| Error[ì—ëŸ¬ ë°˜í™˜]
    
    Detect -->|ë„¤ì´ë²„ ì‡¼í•‘| NaverScraper[ë„¤ì´ë²„ ìŠ¤í¬ë˜í¼]
    Detect -->|iHerb| IHerbScraper[iHerb ìŠ¤í¬ë˜í¼]
    Detect -->|ì•Œ ìˆ˜ ì—†ìŒ| Error
    
    NaverScraper --> ParseHTML[HTML íŒŒì‹±]
    IHerbScraper --> ParseHTML
    
    ParseHTML --> Extract[ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ]
    Extract --> ExtractText[ë¦¬ë·° í…ìŠ¤íŠ¸]
    Extract --> ExtractTags[íƒœê·¸ ì •ë³´]
    Extract --> ExtractMeta[ë©”íƒ€ë°ì´í„°]
    
    ExtractText --> Clean[ë°ì´í„° ì •ì œ]
    ExtractTags --> Clean
    ExtractMeta --> Clean
    
    Clean --> RemoveDup[ì¤‘ë³µ ì œê±°]
    RemoveDup --> Normalize[íƒœê·¸ ì •ê·œí™”]
    Normalize --> Format[CSV í˜•ì‹ ë³€í™˜]
    Format --> Save[CSV íŒŒì¼ ì €ì¥]
    Save --> End[ì™„ë£Œ]
    
    Error --> End
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
data_manager/
â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ scraper.py               # ë©”ì¸ ìŠ¤í¬ë˜í¼ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ BaseScraper          # ê¸°ë³¸ ìŠ¤í¬ë˜í¼ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ NaverScraper         # ë„¤ì´ë²„ ì‡¼í•‘ ìŠ¤í¬ë˜í¼
â”‚   â””â”€â”€ IHerbScraper         # iHerb ìŠ¤í¬ë˜í¼
â”œâ”€â”€ data_cleaner.py          # ë°ì´í„° ì •ì œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ ReviewCleaner        # ë¦¬ë·° ì •ì œ í´ë˜ìŠ¤
â”‚   â””â”€â”€ TagNormalizer        # íƒœê·¸ ì •ê·œí™” í´ë˜ìŠ¤
â”œâ”€â”€ utils.py                 # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ url_validator        # URL ê²€ì¦ í•¨ìˆ˜
â”‚   â”œâ”€â”€ url_type_detector    # URL íƒ€ì… ê°ì§€
â”‚   â””â”€â”€ error_handler        # ì—ëŸ¬ í•¸ë“¤ë§
â””â”€â”€ config.py                # ì„¤ì • íŒŒì¼
    â”œâ”€â”€ SCRAPING_CONFIG      # ìŠ¤í¬ë˜í•‘ ì„¤ì •
    â””â”€â”€ DELAY_SETTINGS       # ìš”ì²­ ì§€ì—° ì„¤ì •
```

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì›¹ ìŠ¤í¬ë˜í•‘:**
  - `selenium` (4.15.0+): ë™ì  í˜ì´ì§€ ì²˜ë¦¬
  - `beautifulsoup4` (4.12.0+): HTML íŒŒì‹±
  - `requests` (2.31.0+): HTTP ìš”ì²­

- **ë°ì´í„° ì²˜ë¦¬:**
  - `pandas` (2.0.0+): CSV ì €ì¥ ë° ë°ì´í„° ì¡°ì‘
  - `lxml` (4.9.0+): XML/HTML íŒŒì„œ

- **ê¸°íƒ€:**
  - `python-dotenv` (1.0.0+): í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
  - `time`: ìš”ì²­ ì§€ì—° ì²˜ë¦¬

---

## ğŸ“ ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜ ì„¤ê³„

### 1. `scraper.py`

#### `BaseScraper` (ì¶”ìƒ í´ë˜ìŠ¤)
```python
class BaseScraper:
    """ëª¨ë“  ìŠ¤í¬ë˜í¼ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, url: str, max_reviews: int = 50):
        """
        Args:
            url: ì œí’ˆ í˜ì´ì§€ URL
            max_reviews: ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ê°œìˆ˜
        """
    
    def scrape(self) -> List[Dict]:
        """ë¦¬ë·° ìˆ˜ì§‘ ë©”ì¸ ë©”ì„œë“œ (ì¶”ìƒ)"""
        pass
    
    def _parse_review(self, review_element) -> Dict:
        """ê°œë³„ ë¦¬ë·° íŒŒì‹± (ì¶”ìƒ)"""
        pass
    
    def _get_review_tags(self, review_element) -> Dict:
        """ë¦¬ë·° íƒœê·¸ ì¶”ì¶œ (ì¬êµ¬ë§¤, í•œë‹¬ì‚¬ìš© ë“±)"""
        pass
```

#### `NaverScraper`
```python
class NaverScraper(BaseScraper):
    """ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ìŠ¤í¬ë˜í¼"""
    
    def scrape(self) -> List[Dict]:
        """
        ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ìˆ˜ì§‘
        
        Returns:
            List[Dict]: ë¦¬ë·° ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            [
                {
                    'text': 'ë¦¬ë·° í…ìŠ¤íŠ¸',
                    'rating': 5,
                    'date': '2024-01-15',
                    'reorder': True,      # ì¬êµ¬ë§¤ ì—¬ë¶€
                    'one_month_use': True, # í•œë‹¬ì‚¬ìš© ì—¬ë¶€
                    'reviewer': 'ì‚¬ìš©ìëª…',
                    'verified': True      # êµ¬ë§¤ ì¸ì¦ ì—¬ë¶€
                },
                ...
            ]
        """
    
    def _parse_review(self, review_element) -> Dict:
        """ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° HTML íŒŒì‹±"""
    
    def _navigate_pages(self) -> List[WebElement]:
        """í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬"""
    
    def _extract_naver_tags(self, review_element) -> Dict:
        """ë„¤ì´ë²„ ì‡¼í•‘ íƒœê·¸ ì¶”ì¶œ"""
```

#### `IHerbScraper`
```python
class IHerbScraper(BaseScraper):
    """iHerb ë¦¬ë·° ìŠ¤í¬ë˜í¼"""
    
    def scrape(self) -> List[Dict]:
        """
        iHerb ë¦¬ë·° ìˆ˜ì§‘
        
        Returns:
            List[Dict]: ë¦¬ë·° ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            [
                {
                    'text': 'ë¦¬ë·° í…ìŠ¤íŠ¸',
                    'rating': 5,
                    'date': '2024-01-15',
                    'reorder': True,
                    'one_month_use': True,
                    'reviewer': 'ì‚¬ìš©ìëª…',
                    'verified': True
                },
                ...
            ]
        """
    
    def _parse_review(self, review_element) -> Dict:
        """iHerb ë¦¬ë·° HTML íŒŒì‹±"""
    
    def _extract_iherb_tags(self, review_element) -> Dict:
        """iHerb íƒœê·¸ ì¶”ì¶œ"""
```

### 2. `data_cleaner.py`

#### `ReviewCleaner`
```python
class ReviewCleaner:
    """ë¦¬ë·° ë°ì´í„° ì •ì œ í´ë˜ìŠ¤"""
    
    def clean(self, reviews: List[Dict]) -> List[Dict]:
        """
        ë¦¬ë·° ë°ì´í„° ì •ì œ
        
        Args:
            reviews: ì›ë³¸ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        
        Returns:
            List[Dict]: ì •ì œëœ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        """
    
    def remove_duplicates(self, reviews: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ë¦¬ë·° ì œê±° (í…ìŠ¤íŠ¸ ê¸°ì¤€)"""
    
    def clean_text(self, text: str) -> str:
        """ë¦¬ë·° í…ìŠ¤íŠ¸ ì •ì œ (íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ì²˜ë¦¬)"""
    
    def validate_review(self, review: Dict) -> bool:
        """ë¦¬ë·° ìœ íš¨ì„± ê²€ì‚¬"""
```

#### `TagNormalizer`
```python
class TagNormalizer:
    """íƒœê·¸ ì •ê·œí™” í´ë˜ìŠ¤"""
    
    def normalize(self, reviews: List[Dict]) -> List[Dict]:
        """
        íƒœê·¸ ì •ë³´ ì •ê·œí™”
        
        - ì¬êµ¬ë§¤: True/Falseë¡œ í†µì¼
        - í•œë‹¬ì‚¬ìš©: True/Falseë¡œ í†µì¼
        """
    
    def extract_reorder_tag(self, review: Dict) -> bool:
        """ì¬êµ¬ë§¤ íƒœê·¸ ì¶”ì¶œ ë° ì •ê·œí™”"""
    
    def extract_usage_period_tag(self, review: Dict) -> bool:
        """ì‚¬ìš© ê¸°ê°„ íƒœê·¸ ì¶”ì¶œ ë° ì •ê·œí™”"""
```

### 3. `utils.py`

```python
def validate_url(url: str) -> bool:
    """URL ìœ íš¨ì„± ê²€ì‚¬"""
    
def detect_url_type(url: str) -> str:
    """
    URL íƒ€ì… ê°ì§€
    
    Returns:
        'naver' | 'iherb' | 'unknown'
    """
    
def create_scraper(url: str, max_reviews: int = 50) -> BaseScraper:
    """
    URL íƒ€ì…ì— ë§ëŠ” ìŠ¤í¬ë˜í¼ ìƒì„±
    
    Returns:
        NaverScraper | IHerbScraper
    """
    
def handle_scraping_error(error: Exception) -> None:
    """ìŠ¤í¬ë˜í•‘ ì—ëŸ¬ í•¸ë“¤ë§"""
```

### 4. ë©”ì¸ í•¨ìˆ˜

```python
def collect_reviews(url: str, max_reviews: int = 50) -> str:
    """
    ë¦¬ë·° ìˆ˜ì§‘ ë° CSV ì €ì¥ ë©”ì¸ í•¨ìˆ˜
    
    Args:
        url: ì œí’ˆ í˜ì´ì§€ URL
        max_reviews: ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ê°œìˆ˜
    
    Returns:
        str: ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ
    """
    # 1. URL ê²€ì¦ ë° íƒ€ì… ê°ì§€
    # 2. ìŠ¤í¬ë˜í¼ ìƒì„±
    # 3. ë¦¬ë·° ìˆ˜ì§‘
    # 4. ë°ì´í„° ì •ì œ
    # 5. CSV ì €ì¥
    # 6. íŒŒì¼ ê²½ë¡œ ë°˜í™˜
```

---

## ğŸ”„ ë°ì´í„° íë¦„

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant Main as collect_reviews()
    participant Scraper as BaseScraper
    participant Cleaner as ReviewCleaner
    participant CSV as CSV Writer
    
    User->>Main: URL, max_reviews ì…ë ¥
    Main->>Main: URL ê²€ì¦ ë° íƒ€ì… ê°ì§€
    Main->>Scraper: ìŠ¤í¬ë˜í¼ ìƒì„±
    Scraper->>Scraper: HTML í˜ì´ì§€ ë¡œë“œ
    Scraper->>Scraper: ë¦¬ë·° ìš”ì†Œ ì¶”ì¶œ
    Scraper->>Scraper: ë¦¬ë·° í…ìŠ¤íŠ¸ íŒŒì‹±
    Scraper->>Scraper: íƒœê·¸ ì •ë³´ ì¶”ì¶œ
    Scraper->>Main: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    Main->>Cleaner: ë°ì´í„° ì •ì œ ìš”ì²­
    Cleaner->>Cleaner: ì¤‘ë³µ ì œê±°
    Cleaner->>Cleaner: í…ìŠ¤íŠ¸ ì •ì œ
    Cleaner->>Cleaner: íƒœê·¸ ì •ê·œí™”
    Cleaner->>Main: ì •ì œëœ ë°ì´í„° ë°˜í™˜
    Main->>CSV: CSV íŒŒì¼ ì €ì¥
    CSV->>User: íŒŒì¼ ê²½ë¡œ ë°˜í™˜
```

---

## ğŸ“Š ë°ì´í„° êµ¬ì¡°

### ì…ë ¥ ë°ì´í„°
- **URL í˜•ì‹:**
  - ë„¤ì´ë²„ ì‡¼í•‘: `https://shopping.naver.com/catalog/...`
  - iHerb: `https://www.iherb.com/pr/...`

### ì¶œë ¥ ë°ì´í„° (CSV)
```csv
text,rating,date,reorder,one_month_use,reviewer,verified,product_url
"ì •ë§ ì¢‹ì€ ì œí’ˆì´ì—ìš”!",5,2024-01-15,True,True,í™ê¸¸ë™,True,https://...
"ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆìŠµë‹ˆë‹¤",4,2024-01-14,True,False,ê¹€ì² ìˆ˜,True,https://...
...
```

### ë¦¬ë·° ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°
```python
{
    'text': str,              # ë¦¬ë·° í…ìŠ¤íŠ¸
    'rating': int,            # í‰ì  (1-5)
    'date': str,              # ì‘ì„±ì¼ (YYYY-MM-DD)
    'reorder': bool,          # ì¬êµ¬ë§¤ ì—¬ë¶€
    'one_month_use': bool,    # í•œë‹¬ ì´ìƒ ì‚¬ìš© ì—¬ë¶€
    'reviewer': str,          # ë¦¬ë·°ì–´ ì´ë¦„
    'verified': bool,         # êµ¬ë§¤ ì¸ì¦ ì—¬ë¶€
    'product_url': str,       # ì œí’ˆ URL
    'review_id': str          # ë¦¬ë·° ê³ ìœ  ID (ì„ íƒ)
}
```

---

## ğŸ› ï¸ êµ¬í˜„ ê°€ì´ë“œ

### 1ë‹¨ê³„: ê¸°ë³¸ ìŠ¤í¬ë˜í¼ êµ¬ì¡° ìƒì„±

```python
# data_manager/scraper.py
from abc import ABC, abstractmethod
from typing import List, Dict
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class BaseScraper(ABC):
    def __init__(self, url: str, max_reviews: int = 50):
        self.url = url
        self.max_reviews = max_reviews
        self.driver = None
    
    @abstractmethod
    def scrape(self) -> List[Dict]:
        pass
    
    def _setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        options.add_argument('--no-sandbox')
        self.driver = webdriver.Chrome(options=options)
    
    def _close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
```

### 2ë‹¨ê³„: ë„¤ì´ë²„ ì‡¼í•‘ ìŠ¤í¬ë˜í¼ êµ¬í˜„

```python
class NaverScraper(BaseScraper):
    def scrape(self) -> List[Dict]:
        """ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ìˆ˜ì§‘"""
        try:
            self._setup_driver()
            self.driver.get(self.url)
            
            reviews = []
            page = 1
            
            while len(reviews) < self.max_reviews:
                # ë¦¬ë·° ìš”ì†Œ ì°¾ê¸°
                review_elements = self.driver.find_elements(
                    By.CSS_SELECTOR, 
                    '.review_list_item'  # ì‹¤ì œ ì…€ë ‰í„°ëŠ” ë„¤ì´ë²„ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
                )
                
                for element in review_elements:
                    if len(reviews) >= self.max_reviews:
                        break
                    review = self._parse_review(element)
                    if review:
                        reviews.append(review)
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if not self._go_to_next_page():
                    break
                page += 1
            
            return reviews
        finally:
            self._close_driver()
    
    def _parse_review(self, element) -> Dict:
        """ê°œë³„ ë¦¬ë·° íŒŒì‹±"""
        # ì‹¤ì œ ë„¤ì´ë²„ ì‡¼í•‘ HTML êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„
        pass
```

### 3ë‹¨ê³„: ë°ì´í„° ì •ì œ ëª¨ë“ˆ êµ¬í˜„

```python
# data_manager/data_cleaner.py
import re
from typing import List, Dict

class ReviewCleaner:
    def clean(self, reviews: List[Dict]) -> List[Dict]:
        """ë¦¬ë·° ë°ì´í„° ì •ì œ"""
        cleaned = []
        seen_texts = set()
        
        for review in reviews:
            # ì¤‘ë³µ ì œê±°
            text = review.get('text', '').strip()
            if text in seen_texts:
                continue
            seen_texts.add(text)
            
            # í…ìŠ¤íŠ¸ ì •ì œ
            review['text'] = self.clean_text(text)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if self.validate_review(review):
                cleaned.append(review)
        
        return cleaned
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (í•„ìš”ì‹œ)
        return text.strip()
    
    def validate_review(self, review: Dict) -> bool:
        """ë¦¬ë·° ìœ íš¨ì„± ê²€ì‚¬"""
        return (
            review.get('text') and 
            len(review.get('text', '')) > 10 and  # ìµœì†Œ ê¸¸ì´
            review.get('rating') is not None
        )
```

### 4ë‹¨ê³„: CSV ì €ì¥ ê¸°ëŠ¥

```python
# data_manager/data_cleaner.py
import pandas as pd
from datetime import datetime

def save_to_csv(reviews: List[Dict], filename: str = None) -> str:
    """
    ë¦¬ë·°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        reviews: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        filename: ì €ì¥í•  íŒŒì¼ëª… (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    
    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if not filename:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'data/reviews/reviews_{timestamp}.csv'
    
    df = pd.DataFrame(reviews)
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    
    return filename
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ì›¹ ìŠ¤í¬ë˜í•‘ ìœ¤ë¦¬
- **ë¡œë´‡ ë°°ì œ í‘œì¤€ ì¤€ìˆ˜:** `robots.txt` í™•ì¸
- **ìš”ì²­ ì§€ì—°:** ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ì„¤ì •
- **User-Agent ì„¤ì •:** ì •ìƒì ì¸ ë¸Œë¼ìš°ì €ë¡œ ì¸ì‹ë˜ë„ë¡ ì„¤ì •

### 2. ì—ëŸ¬ í•¸ë“¤ë§
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì²˜ë¦¬
- í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘
- íƒ€ì„ì•„ì›ƒ ì„¤ì •

### 3. ì„±ëŠ¥ ìµœì í™”
- í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì‚¬ìš© (í•„ìš”ì‹œ)
- ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ë¡œë”© ë°©ì§€
- ë°°ì¹˜ ì²˜ë¦¬

### 4. ë°ì´í„° í’ˆì§ˆ
- ìµœì†Œ ë¦¬ë·° ê¸¸ì´ ê²€ì¦
- í‰ì  ë²”ìœ„ ê²€ì¦
- ë‚ ì§œ í˜•ì‹ í†µì¼

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```python
# tests/test_scraper.py
from data_manager.scraper import NaverScraper, IHerbScraper
from data_manager.utils import detect_url_type

def test_naver_scraper():
    url = "https://shopping.naver.com/catalog/..."
    scraper = NaverScraper(url, max_reviews=10)
    reviews = scraper.scrape()
    
    assert len(reviews) > 0
    assert 'text' in reviews[0]
    assert 'rating' in reviews[0]

def test_url_detection():
    naver_url = "https://shopping.naver.com/..."
    iherb_url = "https://www.iherb.com/pr/..."
    
    assert detect_url_type(naver_url) == 'naver'
    assert detect_url_type(iherb_url) == 'iherb'
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Selenium ê³µì‹ ë¬¸ì„œ](https://www.selenium.dev/documentation/)
- [BeautifulSoup ë¬¸ì„œ](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Pandas CSV ì²˜ë¦¬](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] BaseScraper ì¶”ìƒ í´ë˜ìŠ¤ êµ¬í˜„
- [ ] NaverScraper êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸
- [ ] IHerbScraper êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸
- [ ] ReviewCleaner êµ¬í˜„
- [ ] TagNormalizer êµ¬í˜„
- [ ] CSV ì €ì¥ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
- [ ] ë¡œê¹… ê¸°ëŠ¥ ì¶”ê°€
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

